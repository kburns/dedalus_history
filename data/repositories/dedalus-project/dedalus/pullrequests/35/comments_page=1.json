{"pagelen": 100, "values": [{"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/11035689.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-11035689"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "Hi Jeff.  2 quick things besides what we discussed today. 1) It looks like one of the early merges went a little awry since there are some non-executable insertions and deletions to core files in the first couple commits here (looks like diff output).  2) It looks like every line of checkpointing.py (at least as displayed by bitbuckets side-by-side) gets modified in the second commit, so the easiest solution to 1 might be to just collapse them both out and add your version of checkpoint.py as a new addition.", "markup": "markdown", "html": "<p>Hi Jeff.  2 quick things besides what we discussed today. 1) It looks like one of the early merges went a little awry since there are some non-executable insertions and deletions to core files in the first couple commits here (looks like diff output).  2) It looks like every line of checkpointing.py (at least as displayed by bitbuckets side-by-side) gets modified in the second commit, so the easiest solution to 1 might be to just collapse them both out and add your version of checkpoint.py as a new addition.</p>", "type": "rendered"}, "created_on": "2015-10-22T01:03:21.860713+00:00", "user": {"display_name": "Keaton Burns", "uuid": "{3d3e64f1-bf12-45df-b655-4543d8fb34c4}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D"}, "html": {"href": "https://bitbucket.org/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:e31a7835-5317-4dfa-8551-f32a06f40279/40f33f99-2b75-4a17-a8c2-07c8d74c7480/128"}}, "nickname": "kburns", "type": "user", "account_id": "557058:e31a7835-5317-4dfa-8551-f32a06f40279"}, "updated_on": "2015-10-22T01:03:21.863376+00:00", "type": "pullrequest_comment", "id": 11035689}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/12481777.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-12481777"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "Jeff,\n    I've been testing out checkpointing in this pull request.  The checkpointing itself (and restarts) works great (thanks Jeff!!!), but I have come across a very odd problem for other outputs.  When I'm doing runs using this PR (I have disabled checkpointing in the run in question, to try and narrow this down), I think that only the first set of normal analysis outputs respects the max_writes/file. \n\nIn particular, I'm doing 20 writes per file normally.  On the main branch of dedalus, this works as intended (just tested) and each file contains exactly 20 writes.  When I switch over to this PR and run the same script, the first output file (set 1) contains 20 writes as intended, but then the second output file contains arbitrarily many writes (all further writes go into set 2).\n\nHere's an h5dump on one of my output files (p0 of 256) in set 1 showing the expected 20 writes/file:\n\n\n```\n#!bash\n\n    h5dump FC_fixed_nrhocz2_Ra1e8_test/slices/slices_s1/slices_s1_p0.h5\n    <...>\n       ATTRIBUTE \"writes\" {\n          DATATYPE  H5T_STD_I64LE\n          DATASPACE  SCALAR\n          DATA {\n          (0): 20\n          }\n       }\n    <...>\n\n```\n\n\nand here is the same in set 2, showing an unexepected 69 writes (corresponding to when I killed the run; it would just keep accumulating otherwise in this same set):\n\n\n```\n#!bash\n\n     h5dump FC_fixed_nrhocz2_Ra1e8_test/slices/slices_s2/slices_s2_p0.h5\n       <...>\n       ATTRIBUTE \"writes\" {\n          DATATYPE  H5T_STD_I64LE\n          DATASPACE  SCALAR\n          DATA {\n          (0): 69\n          }\n       }\n\n    <...> \n\n```\n\nBizarrely, if I do the same tests and include checkpointing, checkpoint files respect the max_writes=1/file, and I get regular checkpoint sets output even though the other output files don't (e.g., I have 48 checkpoint sets, s1 -- s48, but still only 2 normal analysis sets, s1 and s2, with 20 writes in s1 and arbitrarily many in s2).\n\nAny ideas where this is coming from?  I'm starting to dive into the PR diffs and my best guess is in evaluator.py.\n\nSorry this isn't more clearly defined; it came up while doing production runs.\n\nWill let you know if I figure anything out,\n--Ben", "markup": "markdown", "html": "<p>Jeff,\n    I've been testing out checkpointing in this pull request.  The checkpointing itself (and restarts) works great (thanks Jeff!!!), but I have come across a very odd problem for other outputs.  When I'm doing runs using this PR (I have disabled checkpointing in the run in question, to try and narrow this down), I think that only the first set of normal analysis outputs respects the max_writes/file. </p>\n<p>In particular, I'm doing 20 writes per file normally.  On the main branch of dedalus, this works as intended (just tested) and each file contains exactly 20 writes.  When I switch over to this PR and run the same script, the first output file (set 1) contains 20 writes as intended, but then the second output file contains arbitrarily many writes (all further writes go into set 2).</p>\n<p>Here's an h5dump on one of my output files (p0 of 256) in set 1 showing the expected 20 writes/file:</p>\n<div class=\"codehilite language-bash\"><pre><span></span>    h5dump FC_fixed_nrhocz2_Ra1e8_test/slices/slices_s1/slices_s1_p0.h5\n    &lt;...&gt;\n       ATTRIBUTE <span class=\"s2\">&quot;writes&quot;</span> <span class=\"o\">{</span>\n          DATATYPE  H5T_STD_I64LE\n          DATASPACE  SCALAR\n          DATA <span class=\"o\">{</span>\n          <span class=\"o\">(</span><span class=\"m\">0</span><span class=\"o\">)</span>: <span class=\"m\">20</span>\n          <span class=\"o\">}</span>\n       <span class=\"o\">}</span>\n    &lt;...&gt;\n</pre></div>\n\n\n<p>and here is the same in set 2, showing an unexepected 69 writes (corresponding to when I killed the run; it would just keep accumulating otherwise in this same set):</p>\n<div class=\"codehilite language-bash\"><pre><span></span>     h5dump FC_fixed_nrhocz2_Ra1e8_test/slices/slices_s2/slices_s2_p0.h5\n       &lt;...&gt;\n       ATTRIBUTE <span class=\"s2\">&quot;writes&quot;</span> <span class=\"o\">{</span>\n          DATATYPE  H5T_STD_I64LE\n          DATASPACE  SCALAR\n          DATA <span class=\"o\">{</span>\n          <span class=\"o\">(</span><span class=\"m\">0</span><span class=\"o\">)</span>: <span class=\"m\">69</span>\n          <span class=\"o\">}</span>\n       <span class=\"o\">}</span>\n\n    &lt;...&gt; \n</pre></div>\n\n\n<p>Bizarrely, if I do the same tests and include checkpointing, checkpoint files respect the max_writes=1/file, and I get regular checkpoint sets output even though the other output files don't (e.g., I have 48 checkpoint sets, s1 -- s48, but still only 2 normal analysis sets, s1 and s2, with 20 writes in s1 and arbitrarily many in s2).</p>\n<p>Any ideas where this is coming from?  I'm starting to dive into the PR diffs and my best guess is in evaluator.py.</p>\n<p>Sorry this isn't more clearly defined; it came up while doing production runs.</p>\n<p>Will let you know if I figure anything out,\n--Ben</p>", "type": "rendered"}, "created_on": "2015-12-05T21:40:25.867394+00:00", "user": {"display_name": "Benjamin Brown", "uuid": "{7ccecdb3-3639-4001-8249-060e80320bda}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B7ccecdb3-3639-4001-8249-060e80320bda%7D"}, "html": {"href": "https://bitbucket.org/%7B7ccecdb3-3639-4001-8249-060e80320bda%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:0696c4b9-e94c-41ac-82be-62ad4f0ec571/8bc6f4da-871a-48b1-88ea-998663d18142/128"}}, "nickname": "Benjamin Brown", "type": "user", "account_id": "557058:0696c4b9-e94c-41ac-82be-62ad4f0ec571"}, "updated_on": "2015-12-05T21:40:25.869223+00:00", "type": "pullrequest_comment", "id": 12481777}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/13050441.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-13050441"}}, "parent": {"id": 12481777, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/12481777.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-12481777"}}, "depth": 1}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "it's this line (363 of evaluator.py) that seems to be the source of the problem:\n\n#!/dedalus-project/dedalus/pull-requests/35/simple-checkpointing-mechanism/diff#Ldedalus/core/evaluator.pyT363\n\nComment this out and we get the normal behaviour, where max_writes is respected, and `self.file_write_num` stays bounded between 1 and `self.max_writes`.  \n\nLeave it in and then writes continue to increment past `self.max_writes`, thereby failing to trigger the write num check at line #!/dedalus-project/dedalus/pull-requests/35/simple-checkpointing-mechanism/diff#Ldedalus/core/evaluator.pyF332T337 \n\nOne solution is to throw a mod statement in, possibly at the assignment statement.  This for example seems to work as a replacement for line 363:\n\n\n```\n#!python\n\nself.file_write_num = h5file['/scales/write_number'][-1] % self.max_writes\n```\n", "markup": "markdown", "html": "<p>it's this line (363 of evaluator.py) that seems to be the source of the problem:</p>\n<p><a href=\"#!/dedalus-project/dedalus/pull-requests/35/simple-checkpointing-mechanism/diff#Ldedalus/core/evaluator.pyT363\" rel=\"nofollow\" class=\"ap-connect-link\">#!/dedalus-project/dedalus/pull-requests/35/simple-checkpointing-mechanism/diff#Ldedalus/core/evaluator.pyT363</a></p>\n<p>Comment this out and we get the normal behaviour, where max_writes is respected, and <code>self.file_write_num</code> stays bounded between 1 and <code>self.max_writes</code>.  </p>\n<p>Leave it in and then writes continue to increment past <code>self.max_writes</code>, thereby failing to trigger the write num check at line <a href=\"#!/dedalus-project/dedalus/pull-requests/35/simple-checkpointing-mechanism/diff#Ldedalus/core/evaluator.pyF332T337\" rel=\"nofollow\" class=\"ap-connect-link\">#!/dedalus-project/dedalus/pull-requests/35/simple-checkpointing-mechanism/diff#Ldedalus/core/evaluator.pyF332T337</a> </p>\n<p>One solution is to throw a mod statement in, possibly at the assignment statement.  This for example seems to work as a replacement for line 363:</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">file_write_num</span> <span class=\"o\">=</span> <span class=\"n\">h5file</span><span class=\"p\">[</span><span class=\"s1\">&#39;/scales/write_number&#39;</span><span class=\"p\">][</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">%</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">max_writes</span>\n</pre></div>", "type": "rendered"}, "created_on": "2015-12-28T04:49:27.236959+00:00", "user": {"display_name": "Benjamin Brown", "uuid": "{7ccecdb3-3639-4001-8249-060e80320bda}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B7ccecdb3-3639-4001-8249-060e80320bda%7D"}, "html": {"href": "https://bitbucket.org/%7B7ccecdb3-3639-4001-8249-060e80320bda%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:0696c4b9-e94c-41ac-82be-62ad4f0ec571/8bc6f4da-871a-48b1-88ea-998663d18142/128"}}, "nickname": "Benjamin Brown", "type": "user", "account_id": "557058:0696c4b9-e94c-41ac-82be-62ad4f0ec571"}, "updated_on": "2015-12-28T04:49:27.239439+00:00", "type": "pullrequest_comment", "id": 13050441}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/13063905.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-13063905"}}, "parent": {"id": 13050441, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/13050441.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-13050441"}}, "depth": 2}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "Good catch. Fixed.", "markup": "markdown", "html": "<p>Good catch. Fixed.</p>", "type": "rendered"}, "created_on": "2015-12-28T17:53:49.386645+00:00", "user": {"display_name": "J. S. Oishi", "uuid": "{ab7c2db2-7642-47a8-9264-0939f601d904}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bab7c2db2-7642-47a8-9264-0939f601d904%7D"}, "html": {"href": "https://bitbucket.org/%7Bab7c2db2-7642-47a8-9264-0939f601d904%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:94f96ca9-adbd-4972-8f41-b00b9683f819/4a90742a-28a5-4829-a074-c23c9f5fcc81/128"}}, "nickname": "jsoishi", "type": "user", "account_id": "557058:94f96ca9-adbd-4972-8f41-b00b9683f819"}, "updated_on": "2015-12-28T17:53:49.388770+00:00", "type": "pullrequest_comment", "id": 13063905}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/13050445.json"}, "code": {"href": "https://api.bitbucket.org/2.0/repositories/dedalus-project/dedalus/diff/jsoishi/dedalus-dev:0ecbf30a88b6..c549dea018ba?path=dedalus%2Fcore%2Fevaluator.py"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-13050445"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "Replace with the following?\n\nself.file_write_num = h5file['/scales/write_number'][-1] % self.max_writes", "markup": "markdown", "html": "<p>Replace with the following?</p>\n<p>self.file_write_num = h5file['/scales/write_number'][-1] % self.max_writes</p>", "type": "rendered"}, "created_on": "2015-12-28T04:49:58.427050+00:00", "user": {"display_name": "Benjamin Brown", "uuid": "{7ccecdb3-3639-4001-8249-060e80320bda}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B7ccecdb3-3639-4001-8249-060e80320bda%7D"}, "html": {"href": "https://bitbucket.org/%7B7ccecdb3-3639-4001-8249-060e80320bda%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:0696c4b9-e94c-41ac-82be-62ad4f0ec571/8bc6f4da-871a-48b1-88ea-998663d18142/128"}}, "nickname": "Benjamin Brown", "type": "user", "account_id": "557058:0696c4b9-e94c-41ac-82be-62ad4f0ec571"}, "inline": {"to": 363, "from": null, "path": "dedalus/core/evaluator.py"}, "updated_on": "2015-12-28T04:49:58.429501+00:00", "type": "pullrequest_comment", "id": 13050445}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/14179599.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-14179599"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "What's the status of this PR?  Is there a hold-up on getting it merged in current condition?\n\n--Ben", "markup": "markdown", "html": "<p>What's the status of this PR?  Is there a hold-up on getting it merged in current condition?</p>\n<p>--Ben</p>", "type": "rendered"}, "created_on": "2016-02-03T18:12:45.322618+00:00", "user": {"display_name": "Benjamin Brown", "uuid": "{7ccecdb3-3639-4001-8249-060e80320bda}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B7ccecdb3-3639-4001-8249-060e80320bda%7D"}, "html": {"href": "https://bitbucket.org/%7B7ccecdb3-3639-4001-8249-060e80320bda%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:0696c4b9-e94c-41ac-82be-62ad4f0ec571/8bc6f4da-871a-48b1-88ea-998663d18142/128"}}, "nickname": "Benjamin Brown", "type": "user", "account_id": "557058:0696c4b9-e94c-41ac-82be-62ad4f0ec571"}, "updated_on": "2016-02-03T18:12:45.328410+00:00", "type": "pullrequest_comment", "id": 14179599}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/14179674.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-14179674"}}, "parent": {"id": 14179599, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/14179599.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-14179599"}}, "depth": 1}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "I think some the issues I mentioned in my first comment are still outstanding -- i.e. issues with the intermediate commits here that would be fixed by a collapse, I think", "markup": "markdown", "html": "<p>I think some the issues I mentioned in my first comment are still outstanding -- i.e. issues with the intermediate commits here that would be fixed by a collapse, I think</p>", "type": "rendered"}, "created_on": "2016-02-03T18:14:41.206097+00:00", "user": {"display_name": "Keaton Burns", "uuid": "{3d3e64f1-bf12-45df-b655-4543d8fb34c4}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D"}, "html": {"href": "https://bitbucket.org/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:e31a7835-5317-4dfa-8551-f32a06f40279/40f33f99-2b75-4a17-a8c2-07c8d74c7480/128"}}, "nickname": "kburns", "type": "user", "account_id": "557058:e31a7835-5317-4dfa-8551-f32a06f40279"}, "updated_on": "2016-02-03T18:14:41.208221+00:00", "type": "pullrequest_comment", "id": 14179674}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/28804243.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-28804243"}}, "parent": {"id": 14179674, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/14179674.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-14179674"}}, "depth": 2}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "bump on getting this resolved and merged?", "markup": "markdown", "html": "<p>bump on getting this resolved and merged?</p>", "type": "rendered"}, "created_on": "2016-12-23T07:23:06.757702+00:00", "user": {"display_name": "Benjamin Brown", "uuid": "{7ccecdb3-3639-4001-8249-060e80320bda}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B7ccecdb3-3639-4001-8249-060e80320bda%7D"}, "html": {"href": "https://bitbucket.org/%7B7ccecdb3-3639-4001-8249-060e80320bda%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:0696c4b9-e94c-41ac-82be-62ad4f0ec571/8bc6f4da-871a-48b1-88ea-998663d18142/128"}}, "nickname": "Benjamin Brown", "type": "user", "account_id": "557058:0696c4b9-e94c-41ac-82be-62ad4f0ec571"}, "updated_on": "2016-12-23T07:23:06.759810+00:00", "type": "pullrequest_comment", "id": 28804243}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/14439382.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-14439382"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "First: I've been using this PR for a few days now -- works great!\n\nI just ran into a problem where I tried to restart a simulation where (I think?) my previous run had created a file but written nothing to it.  Not exactly sure.  It was weird.  BUT changing lines 99-100 of checkpointing.py to:\n\n```\n#!python\nif len(c) > 0 and len(s) > 0:\n    counts[d.name] = c.max()\n    sets[d.name] = s.max()\n```\nfixed the problem.  I had zero-length c's and s's, and it was exploding repeatedly.  Not sure WHY they were zero-length.\n", "markup": "markdown", "html": "<p>First: I've been using this PR for a few days now -- works great!</p>\n<p>I just ran into a problem where I tried to restart a simulation where (I think?) my previous run had created a file but written nothing to it.  Not exactly sure.  It was weird.  BUT changing lines 99-100 of checkpointing.py to:</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">c</span><span class=\"p\">)</span> <span class=\"o\">&gt;</span> <span class=\"mi\">0</span> <span class=\"ow\">and</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">)</span> <span class=\"o\">&gt;</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n    <span class=\"n\">counts</span><span class=\"p\">[</span><span class=\"n\">d</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">()</span>\n    <span class=\"n\">sets</span><span class=\"p\">[</span><span class=\"n\">d</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">s</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">()</span>\n</pre></div>\n\n\n<p>fixed the problem.  I had zero-length c's and s's, and it was exploding repeatedly.  Not sure WHY they were zero-length.</p>", "type": "rendered"}, "created_on": "2016-02-11T02:59:34.988207+00:00", "user": {"display_name": "Evan Anders", "uuid": "{ce45a673-fcc9-48fc-a547-f4ee9f3a8020}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D"}, "html": {"href": "https://bitbucket.org/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:320d4568-38ec-40ab-9264-ac9b3760572a/7e7ec364-57a7-4b6a-809c-b17a66066163/128"}}, "nickname": "evanhanders", "type": "user", "account_id": "557058:320d4568-38ec-40ab-9264-ac9b3760572a"}, "updated_on": "2016-02-11T02:59:35.059701+00:00", "type": "pullrequest_comment", "id": 14439382}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/14482311.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-14482311"}}, "parent": {"id": 14439382, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/14439382.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-14439382"}}, "depth": 1}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "By the way -- this was a vague comment.  I'm going to re-run the simulation I did  and see if the problem is reproduce-able.  Probably won't know for sure until at least the weekend.  It was a ~12 hour run on Janus.\n\nUPDATE: Problem was re-produceable.  Sending an e-mail to Jeff with the files necessary to recreate it.", "markup": "markdown", "html": "<p>By the way -- this was a vague comment.  I'm going to re-run the simulation I did  and see if the problem is reproduce-able.  Probably won't know for sure until at least the weekend.  It was a ~12 hour run on Janus.</p>\n<p>UPDATE: Problem was re-produceable.  Sending an e-mail to Jeff with the files necessary to recreate it.</p>", "type": "rendered"}, "created_on": "2016-02-11T20:59:39.378521+00:00", "user": {"display_name": "Evan Anders", "uuid": "{ce45a673-fcc9-48fc-a547-f4ee9f3a8020}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D"}, "html": {"href": "https://bitbucket.org/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:320d4568-38ec-40ab-9264-ac9b3760572a/7e7ec364-57a7-4b6a-809c-b17a66066163/128"}}, "nickname": "evanhanders", "type": "user", "account_id": "557058:320d4568-38ec-40ab-9264-ac9b3760572a"}, "updated_on": "2016-02-13T18:46:12.526385+00:00", "type": "pullrequest_comment", "id": 14482311}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/19682081.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-19682081"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "I've finally figured out what the above bug was.  Not sure if it's a bug or if it's just me not using checkpointing as intended.  To keep my runs separate and clean, I've been saving everything related to one run in the same subdirectory.\n\nSo, say I have a run with output tasks 'scalar' and 'profiles' stored in 'FC_poly_Ra1e6', then once I start checkpointing I have FC_poly_Ra1e6/scalar, FC_poly_Ra1e6/profiles, and FC_poly_Ra1e6/checkpoint.  When I go to do data analysis (say, analyze fluxes from profiles/ and plot those up special), I'll create a new subdirectory, e.g. FC_poly_Ra1e6/fluxes and put the data in there.\n\nThe problem is that when we get subdirs in line 80 of checkpointing.py, it now grabs /fluxes/ and tries to checkpoint it.  Which causes an insta-crash.  Which makes me sad.\n\nSo there are really two solutions:\n\n1. Tell me to stop outputting the way I'm outputting (which is fine, but I think it's a natural-ish way of organizing data and someone down the road will probably do it, too.  But I'm fine with rearranging now that I know what's happening)\n2. Add a feature to checkpointing so you can specify which subdirectories we actually care about.\n\nI've personally implemented the latter in my local copy of Jeff's directory.  I'm about to send the file to Jeff in an e-mail, and if he likes the changes he can slot it in to his repo/PR.\n \nChanges:\n \n* I've added a new kwarg to Checkpoint's __init__ function, 'allowed_dirs=[]'.  It's an empty list.\n* I've added a description of it to the docstring:\n```\n#!python\n '''\n allowed_dirs : list, optional\n             If there are directories OTHER than dedalus output directories in the specified data_dir, checkpointing\n                 will crash on initialization.  This is a full list of non-checkpointing directories used in the \n                 dedalus run (e.g. ['scalars', 'profiles'])\n '''\n```\n* I've added it to the class' elements in the __init__ function:\n```\n#!python\n           self.allowed_dirs = allowed_dirs\n```\n* I've updated the conditional at line 80 in find_output_counts to check if the user has specified which directories to checkpoint:\n```\n#!python \n         if len(self.allowed_dirs) > 0:\n             subdirs = [x for x in self.data_dir.iterdir() if x.is_dir() and (x.name != \"checkpoint\" and x.name in self.allowed_dirs)]\n         else:\n            subdirs = [x for x in self.data_dir.iterdir() if x.is_dir() and x.name != \"checkpoint\"]\n```\n\n\nI apologize for being so...uh...vague with my earlier \"bug report.\"  Life gets busy and the work-around (sort of) worked.  Anyways, this works more robustly, fixes my case, and still maintains the integrity of checkpointing in general cases.  Hope this helps!\n\n", "markup": "markdown", "html": "<p>I've finally figured out what the above bug was.  Not sure if it's a bug or if it's just me not using checkpointing as intended.  To keep my runs separate and clean, I've been saving everything related to one run in the same subdirectory.</p>\n<p>So, say I have a run with output tasks 'scalar' and 'profiles' stored in 'FC_poly_Ra1e6', then once I start checkpointing I have FC_poly_Ra1e6/scalar, FC_poly_Ra1e6/profiles, and FC_poly_Ra1e6/checkpoint.  When I go to do data analysis (say, analyze fluxes from profiles/ and plot those up special), I'll create a new subdirectory, e.g. FC_poly_Ra1e6/fluxes and put the data in there.</p>\n<p>The problem is that when we get subdirs in line 80 of checkpointing.py, it now grabs /fluxes/ and tries to checkpoint it.  Which causes an insta-crash.  Which makes me sad.</p>\n<p>So there are really two solutions:</p>\n<ol>\n<li>Tell me to stop outputting the way I'm outputting (which is fine, but I think it's a natural-ish way of organizing data and someone down the road will probably do it, too.  But I'm fine with rearranging now that I know what's happening)</li>\n<li>Add a feature to checkpointing so you can specify which subdirectories we actually care about.</li>\n</ol>\n<p>I've personally implemented the latter in my local copy of Jeff's directory.  I'm about to send the file to Jeff in an e-mail, and if he likes the changes he can slot it in to his repo/PR.</p>\n<p>Changes:</p>\n<ul>\n<li>I've added a new kwarg to Checkpoint's <strong>init</strong> function, 'allowed_dirs=[]'.  It's an empty list.</li>\n<li>I've added a description of it to the docstring:</li>\n</ul>\n<div class=\"codehilite language-python\"><pre><span></span> <span class=\"sd\">&#39;&#39;&#39;</span>\n<span class=\"sd\"> allowed_dirs : list, optional</span>\n<span class=\"sd\">             If there are directories OTHER than dedalus output directories in the specified data_dir, checkpointing</span>\n<span class=\"sd\">                 will crash on initialization.  This is a full list of non-checkpointing directories used in the </span>\n<span class=\"sd\">                 dedalus run (e.g. [&#39;scalars&#39;, &#39;profiles&#39;])</span>\n<span class=\"sd\"> &#39;&#39;&#39;</span>\n</pre></div>\n\n\n<ul>\n<li>I've added it to the class' elements in the <strong>init</strong> function:</li>\n</ul>\n<div class=\"codehilite language-python\"><pre><span></span>           <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">allowed_dirs</span> <span class=\"o\">=</span> <span class=\"n\">allowed_dirs</span>\n</pre></div>\n\n\n<ul>\n<li>I've updated the conditional at line 80 in find_output_counts to check if the user has specified which directories to checkpoint:</li>\n</ul>\n<div class=\"codehilite language-python\"><pre><span></span>         <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">allowed_dirs</span><span class=\"p\">)</span> <span class=\"o\">&gt;</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n             <span class=\"n\">subdirs</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">x</span> <span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">data_dir</span><span class=\"o\">.</span><span class=\"n\">iterdir</span><span class=\"p\">()</span> <span class=\"k\">if</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">is_dir</span><span class=\"p\">()</span> <span class=\"ow\">and</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">name</span> <span class=\"o\">!=</span> <span class=\"s2\">&quot;checkpoint&quot;</span> <span class=\"ow\">and</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">name</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">allowed_dirs</span><span class=\"p\">)]</span>\n         <span class=\"k\">else</span><span class=\"p\">:</span>\n            <span class=\"n\">subdirs</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">x</span> <span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">data_dir</span><span class=\"o\">.</span><span class=\"n\">iterdir</span><span class=\"p\">()</span> <span class=\"k\">if</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">is_dir</span><span class=\"p\">()</span> <span class=\"ow\">and</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">name</span> <span class=\"o\">!=</span> <span class=\"s2\">&quot;checkpoint&quot;</span><span class=\"p\">]</span>\n</pre></div>\n\n\n<p>I apologize for being so...uh...vague with my earlier \"bug report.\"  Life gets busy and the work-around (sort of) worked.  Anyways, this works more robustly, fixes my case, and still maintains the integrity of checkpointing in general cases.  Hope this helps!</p>", "type": "rendered"}, "created_on": "2016-06-13T17:01:24.990732+00:00", "user": {"display_name": "Evan Anders", "uuid": "{ce45a673-fcc9-48fc-a547-f4ee9f3a8020}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D"}, "html": {"href": "https://bitbucket.org/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:320d4568-38ec-40ab-9264-ac9b3760572a/7e7ec364-57a7-4b6a-809c-b17a66066163/128"}}, "nickname": "evanhanders", "type": "user", "account_id": "557058:320d4568-38ec-40ab-9264-ac9b3760572a"}, "updated_on": "2016-06-13T17:01:25.126682+00:00", "type": "pullrequest_comment", "id": 19682081}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/20515082.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-20515082"}}, "parent": {"id": 19682081, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/19682081.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-19682081"}}, "depth": 1}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "Hi Evan,\n\nThanks for the robust bug report and potential fix. I've tested your fix, but I've made one change. Rather than making a list of allowed_dirs and not restarting all others, I've reversed the logic to have an excluded_dirs list. This way, by default it will pick everything up. I think your use case might be the less common one. Regardless, this way, if you do something wrong, the simulation will simply die immediately. With the allowed_dirs method, if you forget to put all the analysis tasks in the allowed_dirs, the simulation will run, but will not continue all those analyses. What do you think?", "markup": "markdown", "html": "<p>Hi Evan,</p>\n<p>Thanks for the robust bug report and potential fix. I've tested your fix, but I've made one change. Rather than making a list of allowed_dirs and not restarting all others, I've reversed the logic to have an excluded_dirs list. This way, by default it will pick everything up. I think your use case might be the less common one. Regardless, this way, if you do something wrong, the simulation will simply die immediately. With the allowed_dirs method, if you forget to put all the analysis tasks in the allowed_dirs, the simulation will run, but will not continue all those analyses. What do you think?</p>", "type": "rendered"}, "created_on": "2016-07-01T15:29:51.942773+00:00", "user": {"display_name": "J. S. Oishi", "uuid": "{ab7c2db2-7642-47a8-9264-0939f601d904}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bab7c2db2-7642-47a8-9264-0939f601d904%7D"}, "html": {"href": "https://bitbucket.org/%7Bab7c2db2-7642-47a8-9264-0939f601d904%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:94f96ca9-adbd-4972-8f41-b00b9683f819/4a90742a-28a5-4829-a074-c23c9f5fcc81/128"}}, "nickname": "jsoishi", "type": "user", "account_id": "557058:94f96ca9-adbd-4972-8f41-b00b9683f819"}, "updated_on": "2016-07-01T15:29:51.947235+00:00", "type": "pullrequest_comment", "id": 20515082}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/20526804.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-20526804"}}, "parent": {"id": 20515082, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/20515082.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-20515082"}}, "depth": 2}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "I like this \"excluded\" logic structure better.  Seems like a good idea to have the sims die rather than silently run and produce unexpected behaviour.", "markup": "markdown", "html": "<p>I like this \"excluded\" logic structure better.  Seems like a good idea to have the sims die rather than silently run and produce unexpected behaviour.</p>", "type": "rendered"}, "created_on": "2016-07-01T21:58:43.810747+00:00", "user": {"display_name": "Benjamin Brown", "uuid": "{7ccecdb3-3639-4001-8249-060e80320bda}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B7ccecdb3-3639-4001-8249-060e80320bda%7D"}, "html": {"href": "https://bitbucket.org/%7B7ccecdb3-3639-4001-8249-060e80320bda%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:0696c4b9-e94c-41ac-82be-62ad4f0ec571/8bc6f4da-871a-48b1-88ea-998663d18142/128"}}, "nickname": "Benjamin Brown", "type": "user", "account_id": "557058:0696c4b9-e94c-41ac-82be-62ad4f0ec571"}, "updated_on": "2016-07-01T21:58:43.815349+00:00", "type": "pullrequest_comment", "id": 20526804}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/20619768.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-20619768"}}, "parent": {"id": 20515082, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/20515082.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-20515082"}}, "depth": 2}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "Jeff,\n\nMakes sense, and I like the structure of picking out \"bad\" directories better than \"good\" ones, too.  It requires the user to be more certain about what they're specifying.  Sounds good to me!", "markup": "markdown", "html": "<p>Jeff,</p>\n<p>Makes sense, and I like the structure of picking out \"bad\" directories better than \"good\" ones, too.  It requires the user to be more certain about what they're specifying.  Sounds good to me!</p>", "type": "rendered"}, "created_on": "2016-07-05T17:01:30.787446+00:00", "user": {"display_name": "Evan Anders", "uuid": "{ce45a673-fcc9-48fc-a547-f4ee9f3a8020}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D"}, "html": {"href": "https://bitbucket.org/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:320d4568-38ec-40ab-9264-ac9b3760572a/7e7ec364-57a7-4b6a-809c-b17a66066163/128"}}, "nickname": "evanhanders", "type": "user", "account_id": "557058:320d4568-38ec-40ab-9264-ac9b3760572a"}, "updated_on": "2016-07-05T17:01:30.827199+00:00", "type": "pullrequest_comment", "id": 20619768}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/21044453.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-21044453"}}, "parent": {"id": 20619768, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/20619768.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-20619768"}}, "depth": 3}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "Hi Evan,\n\nI pushed the fix. Please let me know if it works. Additionally, in order to address the commit messes earlier in this PR, I'm probably going to have to rewrite history here, which will propagate back in if you or Ben or any of the other users of this feature don't also excise with me. Thus, I'm not going to merge this PR now, but I'll do it when I return to NYC next week and have time to carefully do all of this.", "markup": "markdown", "html": "<p>Hi Evan,</p>\n<p>I pushed the fix. Please let me know if it works. Additionally, in order to address the commit messes earlier in this PR, I'm probably going to have to rewrite history here, which will propagate back in if you or Ben or any of the other users of this feature don't also excise with me. Thus, I'm not going to merge this PR now, but I'll do it when I return to NYC next week and have time to carefully do all of this.</p>", "type": "rendered"}, "created_on": "2016-07-14T21:33:31.790016+00:00", "user": {"display_name": "J. S. Oishi", "uuid": "{ab7c2db2-7642-47a8-9264-0939f601d904}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bab7c2db2-7642-47a8-9264-0939f601d904%7D"}, "html": {"href": "https://bitbucket.org/%7Bab7c2db2-7642-47a8-9264-0939f601d904%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:94f96ca9-adbd-4972-8f41-b00b9683f819/4a90742a-28a5-4829-a074-c23c9f5fcc81/128"}}, "nickname": "jsoishi", "type": "user", "account_id": "557058:94f96ca9-adbd-4972-8f41-b00b9683f819"}, "updated_on": "2016-07-14T21:33:31.793655+00:00", "type": "pullrequest_comment", "id": 21044453}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/21044592.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-21044592"}}, "parent": {"id": 21044453, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/21044453.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-21044453"}}, "depth": 4}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "The new update works!  Things checkpoint smoothly and don't crash when there are other directories around.  Thanks for the fix.   No worries about merging until you're home.", "markup": "markdown", "html": "<p>The new update works!  Things checkpoint smoothly and don't crash when there are other directories around.  Thanks for the fix.   No worries about merging until you're home.</p>", "type": "rendered"}, "created_on": "2016-07-14T21:37:13.697036+00:00", "user": {"display_name": "Evan Anders", "uuid": "{ce45a673-fcc9-48fc-a547-f4ee9f3a8020}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D"}, "html": {"href": "https://bitbucket.org/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:320d4568-38ec-40ab-9264-ac9b3760572a/7e7ec364-57a7-4b6a-809c-b17a66066163/128"}}, "nickname": "evanhanders", "type": "user", "account_id": "557058:320d4568-38ec-40ab-9264-ac9b3760572a"}, "updated_on": "2016-07-14T21:37:13.740130+00:00", "type": "pullrequest_comment", "id": 21044592}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/21169215.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-21169215"}}, "parent": {"id": 21044453, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/21044453.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-21044453"}}, "depth": 4}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "Sounds great.  Thanks for all your work on this Jeff.", "markup": "markdown", "html": "<p>Sounds great.  Thanks for all your work on this Jeff.</p>", "type": "rendered"}, "created_on": "2016-07-19T05:42:05.778487+00:00", "user": {"display_name": "Benjamin Brown", "uuid": "{7ccecdb3-3639-4001-8249-060e80320bda}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B7ccecdb3-3639-4001-8249-060e80320bda%7D"}, "html": {"href": "https://bitbucket.org/%7B7ccecdb3-3639-4001-8249-060e80320bda%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:0696c4b9-e94c-41ac-82be-62ad4f0ec571/8bc6f4da-871a-48b1-88ea-998663d18142/128"}}, "nickname": "Benjamin Brown", "type": "user", "account_id": "557058:0696c4b9-e94c-41ac-82be-62ad4f0ec571"}, "updated_on": "2016-07-19T05:42:05.783602+00:00", "type": "pullrequest_comment", "id": 21169215}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/29802732.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-29802732"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "Hi all.  Taking another look at this, it seems like the essential functionality is in the find_output_counts function, which gets the final set and count numbers for any analysis subdirectories.  These get handed back to the user, who then uses them to initialize the corresponding output handlers for the restarted runs.  Is that right?  \n\nIf so, it seems like this could be more simply accomplished by adding a keyword option to the file handler initialization that allows you to specify that the handler should say \"append\" to any current outputs or \"overwrite\" them etc.  This would eliminate the need to exclude other subdirectories, since each handler would just individually check if there's previous output in its own target directory.  It would also eliminate the need for the user to manually grab and then re-pass the set and count numbers, which could become a pain to handle manually (i.e. consider the example problem, but with a dozen different analysis handlers).  Any thoughts?", "markup": "markdown", "html": "<p>Hi all.  Taking another look at this, it seems like the essential functionality is in the find_output_counts function, which gets the final set and count numbers for any analysis subdirectories.  These get handed back to the user, who then uses them to initialize the corresponding output handlers for the restarted runs.  Is that right?  </p>\n<p>If so, it seems like this could be more simply accomplished by adding a keyword option to the file handler initialization that allows you to specify that the handler should say \"append\" to any current outputs or \"overwrite\" them etc.  This would eliminate the need to exclude other subdirectories, since each handler would just individually check if there's previous output in its own target directory.  It would also eliminate the need for the user to manually grab and then re-pass the set and count numbers, which could become a pain to handle manually (i.e. consider the example problem, but with a dozen different analysis handlers).  Any thoughts?</p>", "type": "rendered"}, "created_on": "2017-01-16T21:36:31.497780+00:00", "user": {"display_name": "Keaton Burns", "uuid": "{3d3e64f1-bf12-45df-b655-4543d8fb34c4}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D"}, "html": {"href": "https://bitbucket.org/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:e31a7835-5317-4dfa-8551-f32a06f40279/40f33f99-2b75-4a17-a8c2-07c8d74c7480/128"}}, "nickname": "kburns", "type": "user", "account_id": "557058:e31a7835-5317-4dfa-8551-f32a06f40279"}, "updated_on": "2017-01-16T21:36:31.499777+00:00", "type": "pullrequest_comment", "id": 29802732}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/29802835.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-29802835"}}, "parent": {"id": 29802732, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/29802732.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-29802732"}}, "depth": 1}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "And to clarify, setting the handler to \"append\" would basically just have it internally do what the Checkpoint class is doing: look for any current output, and use the last set/count number to initialize the output on the restarted run, or similar.", "markup": "markdown", "html": "<p>And to clarify, setting the handler to \"append\" would basically just have it internally do what the Checkpoint class is doing: look for any current output, and use the last set/count number to initialize the output on the restarted run, or similar.</p>", "type": "rendered"}, "created_on": "2017-01-16T21:38:52.100134+00:00", "user": {"display_name": "Keaton Burns", "uuid": "{3d3e64f1-bf12-45df-b655-4543d8fb34c4}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D"}, "html": {"href": "https://bitbucket.org/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:e31a7835-5317-4dfa-8551-f32a06f40279/40f33f99-2b75-4a17-a8c2-07c8d74c7480/128"}}, "nickname": "kburns", "type": "user", "account_id": "557058:e31a7835-5317-4dfa-8551-f32a06f40279"}, "updated_on": "2017-01-16T21:38:52.102412+00:00", "type": "pullrequest_comment", "id": 29802835}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/29803254.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-29803254"}}, "parent": {"id": 29802835, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/29802835.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-29802835"}}, "depth": 2}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "The append solution seems like a nice and clean one.", "markup": "markdown", "html": "<p>The append solution seems like a nice and clean one.</p>", "type": "rendered"}, "created_on": "2017-01-16T21:50:08.405496+00:00", "user": {"display_name": "Benjamin Brown", "uuid": "{7ccecdb3-3639-4001-8249-060e80320bda}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B7ccecdb3-3639-4001-8249-060e80320bda%7D"}, "html": {"href": "https://bitbucket.org/%7B7ccecdb3-3639-4001-8249-060e80320bda%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:0696c4b9-e94c-41ac-82be-62ad4f0ec571/8bc6f4da-871a-48b1-88ea-998663d18142/128"}}, "nickname": "Benjamin Brown", "type": "user", "account_id": "557058:0696c4b9-e94c-41ac-82be-62ad4f0ec571"}, "updated_on": "2017-01-16T21:50:08.435516+00:00", "type": "pullrequest_comment", "id": 29803254}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/29803446.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-29803446"}}, "parent": {"id": 29803254, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35/comments/29803254.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35/_/diff#comment-29803254"}}, "depth": 3}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 35, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/pullrequests/35.json"}, "html": {"href": "#!/dedalus-project/dedalus/pull-requests/35"}}, "title": "Simple Checkpointing mechanism"}, "content": {"raw": "This would also give flexiblity for a few other types of things too -- in general, there may be analysis outputs that occured after the last checkpoint in the original simulation (if the analysis cadence is shorter than the checkpoint cadence), so you may want to either overwrite those outputs with new data from the restart.  Or you might want to hang on to them and really append to the last output of every handler, which is what it looks like the checkpoint code currently does, but will result in some overlapping outputs from the old and new simulations. ", "markup": "markdown", "html": "<p>This would also give flexiblity for a few other types of things too -- in general, there may be analysis outputs that occured after the last checkpoint in the original simulation (if the analysis cadence is shorter than the checkpoint cadence), so you may want to either overwrite those outputs with new data from the restart.  Or you might want to hang on to them and really append to the last output of every handler, which is what it looks like the checkpoint code currently does, but will result in some overlapping outputs from the old and new simulations. </p>", "type": "rendered"}, "created_on": "2017-01-16T21:55:07.020156+00:00", "user": {"display_name": "Keaton Burns", "uuid": "{3d3e64f1-bf12-45df-b655-4543d8fb34c4}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D"}, "html": {"href": "https://bitbucket.org/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:e31a7835-5317-4dfa-8551-f32a06f40279/40f33f99-2b75-4a17-a8c2-07c8d74c7480/128"}}, "nickname": "kburns", "type": "user", "account_id": "557058:e31a7835-5317-4dfa-8551-f32a06f40279"}, "updated_on": "2017-01-16T21:55:07.022743+00:00", "type": "pullrequest_comment", "id": 29803446}], "page": 1, "size": 21}