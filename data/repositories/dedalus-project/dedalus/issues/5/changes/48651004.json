{"changes": {"content": {"new": "Joe Werne (who really knows a lot about what he's doing) does something equivalent to the following with IO:\r\n\r\nWe're going to want the data in different formats, orderings, FFT spaces, reductions etc.  \r\n\r\nWhen it's an IO time step, it's a good idea to have the compute cores dump out their data in the format they happen to have it in at the time.  After that, a smaller number of dedicated analysis cores clean up and package the data into the format requested by the user.  \r\n\r\nI.e., Given the user's requested data product, the analysis cores ask for raw data from the compute cores at a point in the compute loop that corresponds closest to the needed type.  The compute cores dump out as fast as possible, and move on.  If we want the compute cores to limit the overall efficiency, then the number of analysis cores will scale in some proportion to the frequency of output, and complexity of reduction. \r\n\r\nAt worst, the compute cores create a backlog for the analysis cores. In this case, at the end of a simulation, the compute cores can switch to analysis and help clear the backlog.", "old": "Joe Werne (who really knows a lot about what he's doing) does something equivalent to the following with IO:\r\n\r\nWe're going to want the data in different formats, orderings, FFT spaces, reductions etc.  \r\n\r\nWhen it's an IO time step, it's a good idea to have the compute cores dump out their data in the format they happen to have it in at the time.  After that, a smaller number of dedicated analysis cores clean up and package the data into the format requested by the user.  \r\n\r\nI.e., Given the user's requested data product, the analysis cores ask for raw data from the compute cores at a point in the compute loop that corresponds closest to the needed type.  The compute cores dump out as fast as possible, and move on.  If we want the compute cores to limit the overall efficiency, then the number of analysis cores will scale in some proportion to the frequency of output, and complexity of reduction. \r\n\r\nAt worst, the compute cores create a backlog for the analysis cores. In this case, at the end of a simulation, the compute cores can switch to analysis and help clear the backlog.  "}, "state": {"new": "on hold", "old": "new"}}, "links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/5/changes/48651004.json"}, "html": {"href": "#!/dedalus-project/dedalus/issues/5#comment-48651004"}}, "issue": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/5.json"}}, "type": "issue", "id": 5, "repository": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus.json"}, "html": {"href": "#!/dedalus-project/dedalus"}, "avatar": {"href": "data/bytebucket.org/ravatar/{1dc39ab6-2798-450d-af2f-e976f94b5794}ts=2009435"}}, "type": "repository", "name": "dedalus", "full_name": "dedalus-project/dedalus", "uuid": "{1dc39ab6-2798-450d-af2f-e976f94b5794}"}, "title": "Allow non-simulation processes to handle e.g. IO"}, "created_on": "2018-10-30T21:13:32.405220+00:00", "user": {"display_name": "Keaton Burns", "uuid": "{3d3e64f1-bf12-45df-b655-4543d8fb34c4}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D"}, "html": {"href": "https://bitbucket.org/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:e31a7835-5317-4dfa-8551-f32a06f40279/40f33f99-2b75-4a17-a8c2-07c8d74c7480/128"}}, "nickname": "kburns", "type": "user", "account_id": "557058:e31a7835-5317-4dfa-8551-f32a06f40279"}, "message": {"raw": null, "markup": "markdown", "html": "", "type": "rendered"}, "type": "issue_change", "id": 48651004}