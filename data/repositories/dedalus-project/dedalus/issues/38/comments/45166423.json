{"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/38/comments/45166423.json"}, "html": {"href": "#!/dedalus-project/dedalus/issues/38#comment-45166423"}}, "issue": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/38.json"}}, "type": "issue", "id": 38, "repository": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus.json"}, "html": {"href": "#!/dedalus-project/dedalus"}, "avatar": {"href": "data/bytebucket.org/ravatar/{1dc39ab6-2798-450d-af2f-e976f94b5794}ts=2009435"}}, "type": "repository", "name": "dedalus", "full_name": "dedalus-project/dedalus", "uuid": "{1dc39ab6-2798-450d-af2f-e976f94b5794}"}, "title": "Slow simulation NS2D over a biperiodic space?"}, "content": {"raw": "Hi Pierre,\n\nThanks for your interest in comparing Dedalus to fluidsim -- it looks like a great project.\n\nIt looks like the version of the script in your repository is currently throwing a singular matrix error because the gauge of the streamfunction isn't specified, so I've modified the equations a bit to set it to zero (script attached).  With those changes, and the default Dedalus settings, I'm seeing a baseline time running the script serially with n=256 of T0 = 4.39 seconds on my laptop.  There are three major improvements I'd recommend making:\n\n1) Dedalus lazily constructs the required transform and transposes plans the first time they are required, which is typically during the first timestep.  This means the first timestep should usually be considered as a startup cost, and not indicative of the simulation speed.  If I simply copy your main loop to run 10 startup iterations, and then time the following 10, I get a time of T1 = 4.25 seconds.  Note this startup cost should become less important at higher resolutions, but maybe more important in parallel (due to transpose planning).\n\n2) The most important thing for improving performance is to set the \"STORE_LU\" option to True in the Dedalus configuration file.  This will store and re-use the LU factorization of the LHS matrices when the timestep is unchanged from the previous iteration.  It is currently off by default (which we should probably change), because the LU factorization library wrapped in Scipy can have an enormous memory footprint, and we were leaning towards stability over speed for the default settings.  Changing this flag, I get a time of T2 = 1.38 seconds.\n\n3) Finally, I noticed you're using the RK443 timestepper.  This is a 4-stage 3rd order Runge-Kutta method, which will be evaluating the RHS expressions and solving the LHS matrices 4 times per iteration.  If you're using the same method for other codes, that's ok, but otherwise it's probably most fair to pick timesteppers with the same number of solves per iteration.  A good substitute might be SBDF3, which is a 3rd order multistep method that only uses one solve per iteration.  Switching to SBDF3, I get a time of T3 = 0.38 seconds.\n\nI'd also point out that Dedalus doesn't implement any fully explicit timesteppers -- they are all IMEX schemes, which may make comparisons to fully explicit codes a little tricky, since you're trading off speed-per-iteration for stability with larger timesteps.  From our previous comparisons, we very roughly expect Dedalus to be 2-4x slower than other implicitly-timestepped Fourier pseudospectral codes -- I think it's fair to say that our focus so far has been optimizing for bounded domains with Chebyshev methods.\n\nBest,\n-Keaton", "markup": "markdown", "html": "<p>Hi Pierre,</p>\n<p>Thanks for your interest in comparing Dedalus to fluidsim -- it looks like a great project.</p>\n<p>It looks like the version of the script in your repository is currently throwing a singular matrix error because the gauge of the streamfunction isn't specified, so I've modified the equations a bit to set it to zero (script attached).  With those changes, and the default Dedalus settings, I'm seeing a baseline time running the script serially with n=256 of T0 = 4.39 seconds on my laptop.  There are three major improvements I'd recommend making:</p>\n<p>1) Dedalus lazily constructs the required transform and transposes plans the first time they are required, which is typically during the first timestep.  This means the first timestep should usually be considered as a startup cost, and not indicative of the simulation speed.  If I simply copy your main loop to run 10 startup iterations, and then time the following 10, I get a time of T1 = 4.25 seconds.  Note this startup cost should become less important at higher resolutions, but maybe more important in parallel (due to transpose planning).</p>\n<p>2) The most important thing for improving performance is to set the \"STORE_LU\" option to True in the Dedalus configuration file.  This will store and re-use the LU factorization of the LHS matrices when the timestep is unchanged from the previous iteration.  It is currently off by default (which we should probably change), because the LU factorization library wrapped in Scipy can have an enormous memory footprint, and we were leaning towards stability over speed for the default settings.  Changing this flag, I get a time of T2 = 1.38 seconds.</p>\n<p>3) Finally, I noticed you're using the RK443 timestepper.  This is a 4-stage 3rd order Runge-Kutta method, which will be evaluating the RHS expressions and solving the LHS matrices 4 times per iteration.  If you're using the same method for other codes, that's ok, but otherwise it's probably most fair to pick timesteppers with the same number of solves per iteration.  A good substitute might be SBDF3, which is a 3rd order multistep method that only uses one solve per iteration.  Switching to SBDF3, I get a time of T3 = 0.38 seconds.</p>\n<p>I'd also point out that Dedalus doesn't implement any fully explicit timesteppers -- they are all IMEX schemes, which may make comparisons to fully explicit codes a little tricky, since you're trading off speed-per-iteration for stability with larger timesteps.  From our previous comparisons, we very roughly expect Dedalus to be 2-4x slower than other implicitly-timestepped Fourier pseudospectral codes -- I think it's fair to say that our focus so far has been optimizing for bounded domains with Chebyshev methods.</p>\n<p>Best,\n-Keaton</p>", "type": "rendered"}, "created_on": "2018-05-02T19:20:41.160198+00:00", "user": {"display_name": "Keaton Burns", "uuid": "{3d3e64f1-bf12-45df-b655-4543d8fb34c4}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D"}, "html": {"href": "https://bitbucket.org/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:e31a7835-5317-4dfa-8551-f32a06f40279/40f33f99-2b75-4a17-a8c2-07c8d74c7480/128"}}, "nickname": "kburns", "type": "user", "account_id": "557058:e31a7835-5317-4dfa-8551-f32a06f40279"}, "updated_on": null, "type": "issue_comment", "id": 45166423}