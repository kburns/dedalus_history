{"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64/comments/52949963.json"}, "html": {"href": "#!/dedalus-project/dedalus/issues/64#comment-52949963"}}, "issue": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64.json"}}, "type": "issue", "id": 64, "repository": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus.json"}, "html": {"href": "#!/dedalus-project/dedalus"}, "avatar": {"href": "data/bytebucket.org/ravatar/{1dc39ab6-2798-450d-af2f-e976f94b5794}ts=2009435"}}, "type": "repository", "name": "dedalus", "full_name": "dedalus-project/dedalus", "uuid": "{1dc39ab6-2798-450d-af2f-e976f94b5794}"}, "title": "NCCs cause strange MPI crashes after commit 4232435 in 3D domains with distributed processor meshes"}, "content": {"raw": "On my local PC It\u2019s giving the same error message as above. On Pleiades it\u2019s always been giving a slightly different error message which comes down to \u201cit\u2019s failing to do the broadcast right,\u201d because some processes are getting \u2018None\u2019 out of the broadcast and that\u2019s causing problems later on. I\u2019ll try building the same stack as you have and see if I can replicate,.\n\n\u200c\n\nOn pleiades, I get the following traceback twice \\(as expected with mesh 2,2\\) \\(although there we build Dedalus on the NASA-built mpi-sgi/mpt module\\):\n\n> Traceback \\(most recent call last\\):  \n> File \"mesh\\_rayleigh\\_benard.py\", line 138, in <module>  \n> solver.step\\(dt\\)  \n> File \"/home1/eanders/dedalus/src/dedalus/dedalus/core/solvers.py\", line 515, in step  \n> self.timestepper.step\\(self, dt\\)  \n> File \"/home1/eanders/dedalus/src/dedalus/dedalus/core/timesteppers.py\", line 111, in step  \n> evaluator.evaluate\\_scheduled\\(\\*\\*evaluator\\_kw\\)  \n> File \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 107, in evaluate\\_scheduled  \n> self.evaluate\\_handlers\\(scheduled\\_handlers, wall\\_time=wall\\_time, sim\\_time=sim\\_time, iteration=iteration, \\*\\*kw\\)  \n> File \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 159, in evaluate\\_handlers  \n> handler.process\\(\\*\\*kw\\)  \n> File \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 557, in process  \n> file = self.get\\_file\\(\\)  \n> File \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 425, in get\\_file  \n> if os.path.exists\\(str\\(self.current\\_path\\)\\):  \n> File \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 451, in current\\_path  \n> folder\\_name = '%s\\_s%i' %\\(self.base\\_path.stem, set\\_num\\)  \n> TypeError: %i format: a number is required, not NoneType\n\nwhich actually does happen later, at the timestep stage rather than the initial handler creation stage. Still, looks like self.set\\_num is being improperly set by a comm.bcast call to None.", "markup": "markdown", "html": "<p>On my local PC It\u2019s giving the same error message as above. On Pleiades it\u2019s always been giving a slightly different error message which comes down to \u201cit\u2019s failing to do the broadcast right,\u201d because some processes are getting \u2018None\u2019 out of the broadcast and that\u2019s causing problems later on. I\u2019ll try building the same stack as you have and see if I can replicate,.</p>\n<p>\u200c</p>\n<p>On pleiades, I get the following traceback twice (as expected with mesh 2,2) (although there we build Dedalus on the NASA-built mpi-sgi/mpt module):</p>\n<blockquote>\n<p>Traceback (most recent call last):<br />\nFile \"mesh_rayleigh_benard.py\", line 138, in &lt;module&gt;<br />\nsolver.step(dt)<br />\nFile \"/home1/eanders/dedalus/src/dedalus/dedalus/core/solvers.py\", line 515, in step<br />\nself.timestepper.step(self, dt)<br />\nFile \"/home1/eanders/dedalus/src/dedalus/dedalus/core/timesteppers.py\", line 111, in step<br />\nevaluator.evaluate_scheduled(**evaluator_kw)<br />\nFile \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 107, in evaluate_scheduled<br />\nself.evaluate_handlers(scheduled_handlers, wall_time=wall_time, sim_time=sim_time, iteration=iteration, **kw)<br />\nFile \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 159, in evaluate_handlers<br />\nhandler.process(**kw)<br />\nFile \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 557, in process<br />\nfile = self.get_file()<br />\nFile \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 425, in get_file<br />\nif os.path.exists(str(self.current_path)):<br />\nFile \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 451, in current_path<br />\nfolder_name = '%s_s%i' %(self.base_path.stem, set_num)<br />\nTypeError: %i format: a number is required, not NoneType</p>\n</blockquote>\n<p>which actually does happen later, at the timestep stage rather than the initial handler creation stage. Still, looks like self.set_num is being improperly set by a comm.bcast call to None.</p>", "type": "rendered"}, "created_on": "2019-07-11T21:13:05.085483+00:00", "user": {"display_name": "Evan Anders", "uuid": "{ce45a673-fcc9-48fc-a547-f4ee9f3a8020}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D"}, "html": {"href": "https://bitbucket.org/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:320d4568-38ec-40ab-9264-ac9b3760572a/7e7ec364-57a7-4b6a-809c-b17a66066163/128"}}, "nickname": "evanhanders", "type": "user", "account_id": "557058:320d4568-38ec-40ab-9264-ac9b3760572a"}, "updated_on": "2019-07-11T22:56:03.384865+00:00", "type": "issue_comment", "id": 52949963}