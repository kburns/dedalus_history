{"pagelen": 100, "values": [{"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64/comments/52947815.json"}, "html": {"href": "#!/dedalus-project/dedalus/issues/64#comment-52947815"}}, "issue": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64.json"}}, "type": "issue", "id": 64, "repository": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus.json"}, "html": {"href": "#!/dedalus-project/dedalus"}, "avatar": {"href": "data/bytebucket.org/ravatar/{1dc39ab6-2798-450d-af2f-e976f94b5794}ts=2009435"}}, "type": "repository", "name": "dedalus", "full_name": "dedalus-project/dedalus", "uuid": "{1dc39ab6-2798-450d-af2f-e976f94b5794}"}, "title": "NCCs cause strange MPI crashes after commit 4232435 in 3D domains with distributed processor meshes"}, "content": {"raw": null, "markup": "markdown", "html": "", "type": "rendered"}, "created_on": "2019-07-11T17:37:27.043906+00:00", "user": {"display_name": "Benjamin Brown", "uuid": "{7ccecdb3-3639-4001-8249-060e80320bda}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B7ccecdb3-3639-4001-8249-060e80320bda%7D"}, "html": {"href": "https://bitbucket.org/%7B7ccecdb3-3639-4001-8249-060e80320bda%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:0696c4b9-e94c-41ac-82be-62ad4f0ec571/8bc6f4da-871a-48b1-88ea-998663d18142/128"}}, "nickname": "Benjamin Brown", "type": "user", "account_id": "557058:0696c4b9-e94c-41ac-82be-62ad4f0ec571"}, "updated_on": null, "type": "issue_comment", "id": 52947815}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64/comments/52948311.json"}, "html": {"href": "#!/dedalus-project/dedalus/issues/64#comment-52948311"}}, "issue": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64.json"}}, "type": "issue", "id": 64, "repository": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus.json"}, "html": {"href": "#!/dedalus-project/dedalus"}, "avatar": {"href": "data/bytebucket.org/ravatar/{1dc39ab6-2798-450d-af2f-e976f94b5794}ts=2009435"}}, "type": "repository", "name": "dedalus", "full_name": "dedalus-project/dedalus", "uuid": "{1dc39ab6-2798-450d-af2f-e976f94b5794}"}, "title": "NCCs cause strange MPI crashes after commit 4232435 in 3D domains with distributed processor meshes"}, "content": {"raw": "Jeff and I took a look at this, and unfortunately we\u2019re worried that it\u2019s some kind of stack problem.  From the trace, it looks like the error is actually happening when the outputs are being created, not during the NCC creation.  It\u2019s puzzling because that commit doesn\u2019t alter evaluator.py and it doesn\u2019t change the broadcasting behavior of the NCC computation \\(which already uses uppercase Bcast\\).  \n\nAlso, I\u2019m able to run both scripts fine with 4 processes on the Flatiron cluster.  Can you reproduce the error with a different stack?  In particular, what version of hdf5 are you using for this one?  I\u2019m getting some weird hdf5 errors with 1.10\\+ on the Flatiron cluster, but version 1.8\\+ works fine.", "markup": "markdown", "html": "<p>Jeff and I took a look at this, and unfortunately we\u2019re worried that it\u2019s some kind of stack problem.  From the trace, it looks like the error is actually happening when the outputs are being created, not during the NCC creation.  It\u2019s puzzling because that commit doesn\u2019t alter evaluator.py and it doesn\u2019t change the broadcasting behavior of the NCC computation (which already uses uppercase Bcast).  </p>\n<p>Also, I\u2019m able to run both scripts fine with 4 processes on the Flatiron cluster.  Can you reproduce the error with a different stack?  In particular, what version of hdf5 are you using for this one?  I\u2019m getting some weird hdf5 errors with 1.10+ on the Flatiron cluster, but version 1.8+ works fine.</p>", "type": "rendered"}, "created_on": "2019-07-11T18:27:07.613657+00:00", "user": {"display_name": "Keaton Burns", "uuid": "{3d3e64f1-bf12-45df-b655-4543d8fb34c4}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D"}, "html": {"href": "https://bitbucket.org/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:e31a7835-5317-4dfa-8551-f32a06f40279/40f33f99-2b75-4a17-a8c2-07c8d74c7480/128"}}, "nickname": "kburns", "type": "user", "account_id": "557058:e31a7835-5317-4dfa-8551-f32a06f40279"}, "updated_on": null, "type": "issue_comment", "id": 52948311}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64/comments/52949540.json"}, "html": {"href": "#!/dedalus-project/dedalus/issues/64#comment-52949540"}}, "issue": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64.json"}}, "type": "issue", "id": 64, "repository": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus.json"}, "html": {"href": "#!/dedalus-project/dedalus"}, "avatar": {"href": "data/bytebucket.org/ravatar/{1dc39ab6-2798-450d-af2f-e976f94b5794}ts=2009435"}}, "type": "repository", "name": "dedalus", "full_name": "dedalus-project/dedalus", "uuid": "{1dc39ab6-2798-450d-af2f-e976f94b5794}"}, "title": "NCCs cause strange MPI crashes after commit 4232435 in 3D domains with distributed processor meshes"}, "content": {"raw": "Yeah, I get this error with a stack built on hdf5 1.10\\+ \\(default apt-get hdf5 from the install script in ubuntu on my local PC, and Ben\u2019s cluster\\_install that our group uses on pleiades both use these newer versions\\). When I install dedalus on hdf5 1.8.13 \\(on local PC and pleiades\\), it\u2026still fails, unfortunately, and it does so in essentially the same way. Since the problems seem to be happening in mpi4py, I also tried reverting that back to 2.0.0 and 3.0.0, but neither one runs \\(with hdf5 1.8\\).\n\nCan you send me the versions of all the stuff that your stack works with on Flatiron? I want to see if I can essentially build the same stack as you have and if my simple- and complex- NCC problems work there.", "markup": "markdown", "html": "<p>Yeah, I get this error with a stack built on hdf5 1.10+ (default apt-get hdf5 from the install script in ubuntu on my local PC, and Ben\u2019s cluster_install that our group uses on pleiades both use these newer versions). When I install dedalus on hdf5 1.8.13 (on local PC and pleiades), it\u2026still fails, unfortunately, and it does so in essentially the same way. Since the problems seem to be happening in mpi4py, I also tried reverting that back to 2.0.0 and 3.0.0, but neither one runs (with hdf5 1.8).</p>\n<p>Can you send me the versions of all the stuff that your stack works with on Flatiron? I want to see if I can essentially build the same stack as you have and if my simple- and complex- NCC problems work there.</p>", "type": "rendered"}, "created_on": "2019-07-11T20:21:46.509576+00:00", "user": {"display_name": "Evan Anders", "uuid": "{ce45a673-fcc9-48fc-a547-f4ee9f3a8020}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D"}, "html": {"href": "https://bitbucket.org/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:320d4568-38ec-40ab-9264-ac9b3760572a/7e7ec364-57a7-4b6a-809c-b17a66066163/128"}}, "nickname": "evanhanders", "type": "user", "account_id": "557058:320d4568-38ec-40ab-9264-ac9b3760572a"}, "updated_on": null, "type": "issue_comment", "id": 52949540}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64/comments/52949819.json"}, "html": {"href": "#!/dedalus-project/dedalus/issues/64#comment-52949819"}}, "issue": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64.json"}}, "type": "issue", "id": 64, "repository": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus.json"}, "html": {"href": "#!/dedalus-project/dedalus"}, "avatar": {"href": "data/bytebucket.org/ravatar/{1dc39ab6-2798-450d-af2f-e976f94b5794}ts=2009435"}}, "type": "repository", "name": "dedalus", "full_name": "dedalus-project/dedalus", "uuid": "{1dc39ab6-2798-450d-af2f-e976f94b5794}"}, "title": "NCCs cause strange MPI crashes after commit 4232435 in 3D domains with distributed processor meshes"}, "content": {"raw": "Is it giving different error messages, or always the same as the one above?  My current flatiron stack uses openmpi-2.1.6, hdf5-1.8.21, fftw-3.3.8, mpi4py-3.0.2, h5py-2.9.0.", "markup": "markdown", "html": "<p>Is it giving different error messages, or always the same as the one above?  My current flatiron stack uses openmpi-2.1.6, hdf5-1.8.21, fftw-3.3.8, mpi4py-3.0.2, h5py-2.9.0.</p>", "type": "rendered"}, "created_on": "2019-07-11T20:57:01.102444+00:00", "user": {"display_name": "Keaton Burns", "uuid": "{3d3e64f1-bf12-45df-b655-4543d8fb34c4}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D"}, "html": {"href": "https://bitbucket.org/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:e31a7835-5317-4dfa-8551-f32a06f40279/40f33f99-2b75-4a17-a8c2-07c8d74c7480/128"}}, "nickname": "kburns", "type": "user", "account_id": "557058:e31a7835-5317-4dfa-8551-f32a06f40279"}, "updated_on": null, "type": "issue_comment", "id": 52949819}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64/comments/52949963.json"}, "html": {"href": "#!/dedalus-project/dedalus/issues/64#comment-52949963"}}, "issue": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64.json"}}, "type": "issue", "id": 64, "repository": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus.json"}, "html": {"href": "#!/dedalus-project/dedalus"}, "avatar": {"href": "data/bytebucket.org/ravatar/{1dc39ab6-2798-450d-af2f-e976f94b5794}ts=2009435"}}, "type": "repository", "name": "dedalus", "full_name": "dedalus-project/dedalus", "uuid": "{1dc39ab6-2798-450d-af2f-e976f94b5794}"}, "title": "NCCs cause strange MPI crashes after commit 4232435 in 3D domains with distributed processor meshes"}, "content": {"raw": "On my local PC It\u2019s giving the same error message as above. On Pleiades it\u2019s always been giving a slightly different error message which comes down to \u201cit\u2019s failing to do the broadcast right,\u201d because some processes are getting \u2018None\u2019 out of the broadcast and that\u2019s causing problems later on. I\u2019ll try building the same stack as you have and see if I can replicate,.\n\n\u200c\n\nOn pleiades, I get the following traceback twice \\(as expected with mesh 2,2\\) \\(although there we build Dedalus on the NASA-built mpi-sgi/mpt module\\):\n\n> Traceback \\(most recent call last\\):  \n> File \"mesh\\_rayleigh\\_benard.py\", line 138, in <module>  \n> solver.step\\(dt\\)  \n> File \"/home1/eanders/dedalus/src/dedalus/dedalus/core/solvers.py\", line 515, in step  \n> self.timestepper.step\\(self, dt\\)  \n> File \"/home1/eanders/dedalus/src/dedalus/dedalus/core/timesteppers.py\", line 111, in step  \n> evaluator.evaluate\\_scheduled\\(\\*\\*evaluator\\_kw\\)  \n> File \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 107, in evaluate\\_scheduled  \n> self.evaluate\\_handlers\\(scheduled\\_handlers, wall\\_time=wall\\_time, sim\\_time=sim\\_time, iteration=iteration, \\*\\*kw\\)  \n> File \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 159, in evaluate\\_handlers  \n> handler.process\\(\\*\\*kw\\)  \n> File \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 557, in process  \n> file = self.get\\_file\\(\\)  \n> File \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 425, in get\\_file  \n> if os.path.exists\\(str\\(self.current\\_path\\)\\):  \n> File \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 451, in current\\_path  \n> folder\\_name = '%s\\_s%i' %\\(self.base\\_path.stem, set\\_num\\)  \n> TypeError: %i format: a number is required, not NoneType\n\nwhich actually does happen later, at the timestep stage rather than the initial handler creation stage. Still, looks like self.set\\_num is being improperly set by a comm.bcast call to None.", "markup": "markdown", "html": "<p>On my local PC It\u2019s giving the same error message as above. On Pleiades it\u2019s always been giving a slightly different error message which comes down to \u201cit\u2019s failing to do the broadcast right,\u201d because some processes are getting \u2018None\u2019 out of the broadcast and that\u2019s causing problems later on. I\u2019ll try building the same stack as you have and see if I can replicate,.</p>\n<p>\u200c</p>\n<p>On pleiades, I get the following traceback twice (as expected with mesh 2,2) (although there we build Dedalus on the NASA-built mpi-sgi/mpt module):</p>\n<blockquote>\n<p>Traceback (most recent call last):<br />\nFile \"mesh_rayleigh_benard.py\", line 138, in &lt;module&gt;<br />\nsolver.step(dt)<br />\nFile \"/home1/eanders/dedalus/src/dedalus/dedalus/core/solvers.py\", line 515, in step<br />\nself.timestepper.step(self, dt)<br />\nFile \"/home1/eanders/dedalus/src/dedalus/dedalus/core/timesteppers.py\", line 111, in step<br />\nevaluator.evaluate_scheduled(**evaluator_kw)<br />\nFile \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 107, in evaluate_scheduled<br />\nself.evaluate_handlers(scheduled_handlers, wall_time=wall_time, sim_time=sim_time, iteration=iteration, **kw)<br />\nFile \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 159, in evaluate_handlers<br />\nhandler.process(**kw)<br />\nFile \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 557, in process<br />\nfile = self.get_file()<br />\nFile \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 425, in get_file<br />\nif os.path.exists(str(self.current_path)):<br />\nFile \"/home1/eanders/dedalus/src/dedalus/dedalus/core/evaluator.py\", line 451, in current_path<br />\nfolder_name = '%s_s%i' %(self.base_path.stem, set_num)<br />\nTypeError: %i format: a number is required, not NoneType</p>\n</blockquote>\n<p>which actually does happen later, at the timestep stage rather than the initial handler creation stage. Still, looks like self.set_num is being improperly set by a comm.bcast call to None.</p>", "type": "rendered"}, "created_on": "2019-07-11T21:13:05.085483+00:00", "user": {"display_name": "Evan Anders", "uuid": "{ce45a673-fcc9-48fc-a547-f4ee9f3a8020}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D"}, "html": {"href": "https://bitbucket.org/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:320d4568-38ec-40ab-9264-ac9b3760572a/7e7ec364-57a7-4b6a-809c-b17a66066163/128"}}, "nickname": "evanhanders", "type": "user", "account_id": "557058:320d4568-38ec-40ab-9264-ac9b3760572a"}, "updated_on": "2019-07-11T22:56:03.384865+00:00", "type": "issue_comment", "id": 52949963}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64/comments/52951450.json"}, "html": {"href": "#!/dedalus-project/dedalus/issues/64#comment-52951450"}}, "issue": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64.json"}}, "type": "issue", "id": 64, "repository": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus.json"}, "html": {"href": "#!/dedalus-project/dedalus"}, "avatar": {"href": "data/bytebucket.org/ravatar/{1dc39ab6-2798-450d-af2f-e976f94b5794}ts=2009435"}}, "type": "repository", "name": "dedalus", "full_name": "dedalus-project/dedalus", "uuid": "{1dc39ab6-2798-450d-af2f-e976f94b5794}"}, "title": "NCCs cause strange MPI crashes after commit 4232435 in 3D domains with distributed processor meshes"}, "content": {"raw": "So I couldn\u2019t get the openmpi version to match exactly without more effort \\(I\u2019m on 2.1.1 instead of 2.1.6\\), and I don\u2019t think I\u2019m going to get to work on this much more tonight.  But I do know that this bug has come up on at least 3 different stacks, and here\u2019s something else that might be related:\n\nFor the problem above, if I put on debug output, the NCC expansion output is VASTLY different between versions 1150 and 1151. If I hg up 1150 and run mpirun -n 4 python3 mesh\\_rayleigh\\_benard.py, here\u2019s how the NCC expansion is reported:\n\n> \u2026\n>\n> 2019-07-11 18:49:57,001 solvers 0/4 DEBUG :: Beginning IVP instantiation  \n> 2019-07-11 18:49:57,021 transposes 0/4 DEBUG :: Building FFTW transpose plan for \\(dtype, gshape, axis\\) = \\(complex128, \\[ 8 16  8\\], 0\\)  \n> 2019-07-11 18:49:57,028 transposes 0/4 DEBUG :: Building FFTW transpose plan for \\(dtype, gshape, axis\\) = \\(complex128, \\[ 4 15 16\\], 1\\)  \n> 2019-07-11 18:49:57,032 basis 0/4 DEBUG :: Building FFTW DCT plan for \\(dtype, gshape, axis\\) = \\(complex128, \\(4, 8, 16\\), 2\\)  \n> 2019-07-11 18:49:57,035 field 0/4 DEBUG :: Expanded NCC 'this\\_ncc' to mode 0 with 1 terms.  \n> 2019-07-11 18:49:57,037 field 0/4 DEBUG :: Expanded NCC 'this\\_ncc\\*\\(-1_P\\)' to mode 0 with 1 terms.  \n> 2019-07-11 18:49:57,038 field 0/4 DEBUG :: Expanded NCC 'this\\_ncc_\\(-1_P\\)' to mode 0 with 1 terms.  \n> 2019-07-11 18:49:57,041 field 0/4 DEBUG :: Expanded NCC 'this\\_ncc_\\(-1_P\\)' to mode 0 with 1 terms.  \n> 2019-07-11 18:49:57,045 field 0/4 DEBUG :: Expanded NCC 'this\\_ncc_\\(-1_R\\)' to mode 0 with 1 terms.  \n> 2019-07-11 18:49:57,047 field 0/4 DEBUG :: Expanded NCC 'this\\_ncc_\\(-1_R\\)' to mode 0 with 1 terms.  \n> 2019-07-11 18:49:57,049 field 0/4 DEBUG :: Expanded NCC 'this\\_ncc_\\(-1_R\\)' to mode 0 with 1 terms.  \n> 2019-07-11 18:49:57,051 field 0/4 DEBUG :: Expanded NCC 'this\\_ncc_\\(-1_R\\)' to mode 0 with 1 terms.  \n> 2019-07-11 18:49:57,053 field 0/4 DEBUG :: Expanded NCC 'this\\_ncc_\\(-1_R\\)' to mode 0 with 1 terms.  \n> 2019-07-11 18:49:57,056 field 0/4 DEBUG :: Expanded NCC 'this\\_ncc_\\(-1_R\\)' to mode 0 with 1 terms.  \n> 2019-07-11 18:49:57,059 field 0/4 DEBUG :: Expanded NCC 'this\\_ncc_\\(-1_R\\)' to mode 0 with 1 terms.  \n> 2019-07-11 18:49:57,062 field 0/4 DEBUG :: Expanded NCC 'this\\_ncc_\\(-1_R\\)' to mode 0 with 1 terms.  \n> 2019-07-11 18:49:57,064 field 0/4 DEBUG :: Expanded NCC 'this\\_ncc_\\(-1_R\\)' to mode 0 with 1 terms.  \n> 2019-07-11 18:49:57,067 field 0/4 DEBUG :: Expanded NCC 'this\\_ncc_-1' to mode 0 with 1 terms.  \n> 2019-07-11 18:49:57,172 pencil 0/4 INFO :: Building pencil matrix 1/32 \\(~3%\\) Elapsed: 0s, Remaining: 3s, Rate: 1.0e\\+01/s  \n> 2019-07-11 18:49:57,531 pencil 0/4 INFO :: Building pencil matrix 4/32 \\(~12%\\) Elapsed: 0s, Remaining: 3s, Rate: 8.8e\\+00/s\n\n\u2026and so on, the pencils build and it goes, and the problem successfully timesteps. But if I run the same command line after doing hg up 1151, the run fails and it seems to expand the NCCs for each pencil? I\u2019ve attached the debug output for that \\(see \u2018much\\_expansion\\_sadness.txt\u2019, attached to original bug report now\\). Jhett and I have been wondering if this was an intentional change to how NCC expansion was reported, but I\u2019m thinking it wasn\u2019t, especially since it starts showing up at the commit where we start having problems with NCCs.  Was that intentional? Any idea why it\u2019s spitting out so much NCC expansion nonsense?", "markup": "markdown", "html": "<p>So I couldn\u2019t get the openmpi version to match exactly without more effort (I\u2019m on 2.1.1 instead of 2.1.6), and I don\u2019t think I\u2019m going to get to work on this much more tonight.  But I do know that this bug has come up on at least 3 different stacks, and here\u2019s something else that might be related:</p>\n<p>For the problem above, if I put on debug output, the NCC expansion output is VASTLY different between versions 1150 and 1151. If I hg up 1150 and run mpirun -n 4 python3 mesh_rayleigh_benard.py, here\u2019s how the NCC expansion is reported:</p>\n<blockquote>\n<p>\u2026</p>\n<p>2019-07-11 18:49:57,001 solvers 0/4 DEBUG :: Beginning IVP instantiation<br />\n2019-07-11 18:49:57,021 transposes 0/4 DEBUG :: Building FFTW transpose plan for (dtype, gshape, axis) = (complex128, [ 8 16  8], 0)<br />\n2019-07-11 18:49:57,028 transposes 0/4 DEBUG :: Building FFTW transpose plan for (dtype, gshape, axis) = (complex128, [ 4 15 16], 1)<br />\n2019-07-11 18:49:57,032 basis 0/4 DEBUG :: Building FFTW DCT plan for (dtype, gshape, axis) = (complex128, (4, 8, 16), 2)<br />\n2019-07-11 18:49:57,035 field 0/4 DEBUG :: Expanded NCC 'this_ncc' to mode 0 with 1 terms.<br />\n2019-07-11 18:49:57,037 field 0/4 DEBUG :: Expanded NCC 'this_ncc*(-1_P)' to mode 0 with 1 terms.<br />\n2019-07-11 18:49:57,038 field 0/4 DEBUG :: Expanded NCC 'this_ncc_(-1_P)' to mode 0 with 1 terms.<br />\n2019-07-11 18:49:57,041 field 0/4 DEBUG :: Expanded NCC 'this_ncc_(-1_P)' to mode 0 with 1 terms.<br />\n2019-07-11 18:49:57,045 field 0/4 DEBUG :: Expanded NCC 'this_ncc_(-1_R)' to mode 0 with 1 terms.<br />\n2019-07-11 18:49:57,047 field 0/4 DEBUG :: Expanded NCC 'this_ncc_(-1_R)' to mode 0 with 1 terms.<br />\n2019-07-11 18:49:57,049 field 0/4 DEBUG :: Expanded NCC 'this_ncc_(-1_R)' to mode 0 with 1 terms.<br />\n2019-07-11 18:49:57,051 field 0/4 DEBUG :: Expanded NCC 'this_ncc_(-1_R)' to mode 0 with 1 terms.<br />\n2019-07-11 18:49:57,053 field 0/4 DEBUG :: Expanded NCC 'this_ncc_(-1_R)' to mode 0 with 1 terms.<br />\n2019-07-11 18:49:57,056 field 0/4 DEBUG :: Expanded NCC 'this_ncc_(-1_R)' to mode 0 with 1 terms.<br />\n2019-07-11 18:49:57,059 field 0/4 DEBUG :: Expanded NCC 'this_ncc_(-1_R)' to mode 0 with 1 terms.<br />\n2019-07-11 18:49:57,062 field 0/4 DEBUG :: Expanded NCC 'this_ncc_(-1_R)' to mode 0 with 1 terms.<br />\n2019-07-11 18:49:57,064 field 0/4 DEBUG :: Expanded NCC 'this_ncc_(-1_R)' to mode 0 with 1 terms.<br />\n2019-07-11 18:49:57,067 field 0/4 DEBUG :: Expanded NCC 'this_ncc_-1' to mode 0 with 1 terms.<br />\n2019-07-11 18:49:57,172 pencil 0/4 INFO :: Building pencil matrix 1/32 (~3%) Elapsed: 0s, Remaining: 3s, Rate: 1.0e+01/s<br />\n2019-07-11 18:49:57,531 pencil 0/4 INFO :: Building pencil matrix 4/32 (~12%) Elapsed: 0s, Remaining: 3s, Rate: 8.8e+00/s</p>\n</blockquote>\n<p>\u2026and so on, the pencils build and it goes, and the problem successfully timesteps. But if I run the same command line after doing hg up 1151, the run fails and it seems to expand the NCCs for each pencil? I\u2019ve attached the debug output for that (see \u2018much_expansion_sadness.txt\u2019, attached to original bug report now). Jhett and I have been wondering if this was an intentional change to how NCC expansion was reported, but I\u2019m thinking it wasn\u2019t, especially since it starts showing up at the commit where we start having problems with NCCs.  Was that intentional? Any idea why it\u2019s spitting out so much NCC expansion nonsense?</p>", "type": "rendered"}, "created_on": "2019-07-12T00:55:01.903679+00:00", "user": {"display_name": "Evan Anders", "uuid": "{ce45a673-fcc9-48fc-a547-f4ee9f3a8020}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D"}, "html": {"href": "https://bitbucket.org/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:320d4568-38ec-40ab-9264-ac9b3760572a/7e7ec364-57a7-4b6a-809c-b17a66066163/128"}}, "nickname": "evanhanders", "type": "user", "account_id": "557058:320d4568-38ec-40ab-9264-ac9b3760572a"}, "updated_on": null, "type": "issue_comment", "id": 52951450}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64/comments/52951454.json"}, "html": {"href": "#!/dedalus-project/dedalus/issues/64#comment-52951454"}}, "issue": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64.json"}}, "type": "issue", "id": 64, "repository": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus.json"}, "html": {"href": "#!/dedalus-project/dedalus"}, "avatar": {"href": "data/bytebucket.org/ravatar/{1dc39ab6-2798-450d-af2f-e976f94b5794}ts=2009435"}}, "type": "repository", "name": "dedalus", "full_name": "dedalus-project/dedalus", "uuid": "{1dc39ab6-2798-450d-af2f-e976f94b5794}"}, "title": "NCCs cause strange MPI crashes after commit 4232435 in 3D domains with distributed processor meshes"}, "content": {"raw": "barfy output of NCC expansion starting at commit 1151 (if I hg up 1150, the output is much cleaner).", "markup": "markdown", "html": "<p>barfy output of NCC expansion starting at commit 1151 (if I hg up 1150, the output is much cleaner).</p>", "type": "rendered"}, "created_on": "2019-07-12T00:55:34.788831+00:00", "user": {"display_name": "Evan Anders", "uuid": "{ce45a673-fcc9-48fc-a547-f4ee9f3a8020}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D"}, "html": {"href": "https://bitbucket.org/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:320d4568-38ec-40ab-9264-ac9b3760572a/7e7ec364-57a7-4b6a-809c-b17a66066163/128"}}, "nickname": "evanhanders", "type": "user", "account_id": "557058:320d4568-38ec-40ab-9264-ac9b3760572a"}, "updated_on": null, "type": "issue_comment", "id": 52951454}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64/comments/52951530.json"}, "html": {"href": "#!/dedalus-project/dedalus/issues/64#comment-52951530"}}, "issue": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64.json"}}, "type": "issue", "id": 64, "repository": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus.json"}, "html": {"href": "#!/dedalus-project/dedalus"}, "avatar": {"href": "data/bytebucket.org/ravatar/{1dc39ab6-2798-450d-af2f-e976f94b5794}ts=2009435"}}, "type": "repository", "name": "dedalus", "full_name": "dedalus-project/dedalus", "uuid": "{1dc39ab6-2798-450d-af2f-e976f94b5794}"}, "title": "NCCs cause strange MPI crashes after commit 4232435 in 3D domains with distributed processor meshes"}, "content": {"raw": "Ah very interesting!  Thanks for pointing this out \u2013 definitely not intentional.  Still not clear to me why it\u2019s ultimately failing, but this is a good lead and I\u2019ll dig into it tomorrow.  Basically the NCC construction was changed to allow dependence on the argument\u2019s metadata, which is necessary for the Hermite/Laguerre bases.  It look like this is preventing the NCC expansions from being cached correctly, so they\u2019re recomputed for every time they appear in the equations and for every pencil.", "markup": "markdown", "html": "<p>Ah very interesting!  Thanks for pointing this out \u2013 definitely not intentional.  Still not clear to me why it\u2019s ultimately failing, but this is a good lead and I\u2019ll dig into it tomorrow.  Basically the NCC construction was changed to allow dependence on the argument\u2019s metadata, which is necessary for the Hermite/Laguerre bases.  It look like this is preventing the NCC expansions from being cached correctly, so they\u2019re recomputed for every time they appear in the equations and for every pencil.</p>", "type": "rendered"}, "created_on": "2019-07-12T01:05:04.577634+00:00", "user": {"display_name": "Keaton Burns", "uuid": "{3d3e64f1-bf12-45df-b655-4543d8fb34c4}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D"}, "html": {"href": "https://bitbucket.org/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:e31a7835-5317-4dfa-8551-f32a06f40279/40f33f99-2b75-4a17-a8c2-07c8d74c7480/128"}}, "nickname": "kburns", "type": "user", "account_id": "557058:e31a7835-5317-4dfa-8551-f32a06f40279"}, "updated_on": null, "type": "issue_comment", "id": 52951530}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64/comments/52972074.json"}, "html": {"href": "#!/dedalus-project/dedalus/issues/64#comment-52972074"}}, "issue": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64.json"}}, "type": "issue", "id": 64, "repository": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus.json"}, "html": {"href": "#!/dedalus-project/dedalus"}, "avatar": {"href": "data/bytebucket.org/ravatar/{1dc39ab6-2798-450d-af2f-e976f94b5794}ts=2009435"}}, "type": "repository", "name": "dedalus", "full_name": "dedalus-project/dedalus", "uuid": "{1dc39ab6-2798-450d-af2f-e976f94b5794}"}, "title": "NCCs cause strange MPI crashes after commit 4232435 in 3D domains with distributed processor meshes"}, "content": {"raw": "Interesting! Let me know what you find, and if you can fix the NCC caching problem. Might be manifesting in the originally reported bug for some reason.  \n  \nThe more I work with this bug, the more I\u2019m feeling like it\u2019s not actually a problem with MPI, but has something to do with something else going subtly wrong\u2026maybe this is it. If it were an MPI problem, then it should fail at 1150 as well \\(the MPI calls don\u2019t change\\).", "markup": "markdown", "html": "<p>Interesting! Let me know what you find, and if you can fix the NCC caching problem. Might be manifesting in the originally reported bug for some reason.  </p>\n<p>The more I work with this bug, the more I\u2019m feeling like it\u2019s not actually a problem with MPI, but has something to do with something else going subtly wrong\u2026maybe this is it. If it were an MPI problem, then it should fail at 1150 as well (the MPI calls don\u2019t change).</p>", "type": "rendered"}, "created_on": "2019-07-13T17:05:45.659782+00:00", "user": {"display_name": "Evan Anders", "uuid": "{ce45a673-fcc9-48fc-a547-f4ee9f3a8020}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D"}, "html": {"href": "https://bitbucket.org/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:320d4568-38ec-40ab-9264-ac9b3760572a/7e7ec364-57a7-4b6a-809c-b17a66066163/128"}}, "nickname": "evanhanders", "type": "user", "account_id": "557058:320d4568-38ec-40ab-9264-ac9b3760572a"}, "updated_on": null, "type": "issue_comment", "id": 52972074}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64/comments/53150407.json"}, "html": {"href": "#!/dedalus-project/dedalus/issues/64#comment-53150407"}}, "issue": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64.json"}}, "type": "issue", "id": 64, "repository": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus.json"}, "html": {"href": "#!/dedalus-project/dedalus"}, "avatar": {"href": "data/bytebucket.org/ravatar/{1dc39ab6-2798-450d-af2f-e976f94b5794}ts=2009435"}}, "type": "repository", "name": "dedalus", "full_name": "dedalus-project/dedalus", "uuid": "{1dc39ab6-2798-450d-af2f-e976f94b5794}"}, "title": "NCCs cause strange MPI crashes after commit 4232435 in 3D domains with distributed processor meshes"}, "content": {"raw": "Ok, I just pushed a few commits implementing a fix to properly cache the NCCs based on just the argument\u2019s z-metadata.  I was able to reproduce the errors on my desktop so I don\u2019t think it was a stack issue at all \u2013 I must not have been using a recent enough build of Dedalus on the flatiron cluster to see it before.  It looks like the bug was causing the code to rebuild the NCCs for every pencil, and this requires communication, so it can deadlock if there\u2019s an imbalanced pencil distribution.  These new commits fix the issue for me, but can you check if they work for you?", "markup": "markdown", "html": "<p>Ok, I just pushed a few commits implementing a fix to properly cache the NCCs based on just the argument\u2019s z-metadata.  I was able to reproduce the errors on my desktop so I don\u2019t think it was a stack issue at all \u2013 I must not have been using a recent enough build of Dedalus on the flatiron cluster to see it before.  It looks like the bug was causing the code to rebuild the NCCs for every pencil, and this requires communication, so it can deadlock if there\u2019s an imbalanced pencil distribution.  These new commits fix the issue for me, but can you check if they work for you?</p>", "type": "rendered"}, "created_on": "2019-07-25T23:47:13.260530+00:00", "user": {"display_name": "Keaton Burns", "uuid": "{3d3e64f1-bf12-45df-b655-4543d8fb34c4}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D"}, "html": {"href": "https://bitbucket.org/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:e31a7835-5317-4dfa-8551-f32a06f40279/40f33f99-2b75-4a17-a8c2-07c8d74c7480/128"}}, "nickname": "kburns", "type": "user", "account_id": "557058:e31a7835-5317-4dfa-8551-f32a06f40279"}, "updated_on": null, "type": "issue_comment", "id": 53150407}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64/comments/53162155.json"}, "html": {"href": "#!/dedalus-project/dedalus/issues/64#comment-53162155"}}, "issue": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64.json"}}, "type": "issue", "id": 64, "repository": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus.json"}, "html": {"href": "#!/dedalus-project/dedalus"}, "avatar": {"href": "data/bytebucket.org/ravatar/{1dc39ab6-2798-450d-af2f-e976f94b5794}ts=2009435"}}, "type": "repository", "name": "dedalus", "full_name": "dedalus-project/dedalus", "uuid": "{1dc39ab6-2798-450d-af2f-e976f94b5794}"}, "title": "NCCs cause strange MPI crashes after commit 4232435 in 3D domains with distributed processor meshes"}, "content": {"raw": "Looks like NCCs are properly caching again! And, with them, the code\u2019s no longer crashing. The simple case here and my fully compressible equations \\(for two different atmospheres with different NCC expansions\\) seem to be up and running again on the tip version of dedalus.\n\nThanks, Keaton!  @{557058:490cfe71-054b-408c-9f37-3fae874b19cc} , do your atmospheres and equations work on the tip version of dedalus now?\n\nI think if Jhett signs off, I\u2019m happy to mark as resolved.", "markup": "markdown", "html": "<p>Looks like NCCs are properly caching again! And, with them, the code\u2019s no longer crashing. The simple case here and my fully compressible equations (for two different atmospheres with different NCC expansions) seem to be up and running again on the tip version of dedalus.</p>\n<p>Thanks, Keaton!  <span class=\"ap-mention\" data-atlassian-id=\"557058:490cfe71-054b-408c-9f37-3fae874b19cc\">@Jhett Bordwell</span> , do your atmospheres and equations work on the tip version of dedalus now?</p>\n<p>I think if Jhett signs off, I\u2019m happy to mark as resolved.</p>", "type": "rendered"}, "created_on": "2019-07-26T16:31:22.806339+00:00", "user": {"display_name": "Evan Anders", "uuid": "{ce45a673-fcc9-48fc-a547-f4ee9f3a8020}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D"}, "html": {"href": "https://bitbucket.org/%7Bce45a673-fcc9-48fc-a547-f4ee9f3a8020%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:320d4568-38ec-40ab-9264-ac9b3760572a/7e7ec364-57a7-4b6a-809c-b17a66066163/128"}}, "nickname": "evanhanders", "type": "user", "account_id": "557058:320d4568-38ec-40ab-9264-ac9b3760572a"}, "updated_on": null, "type": "issue_comment", "id": 53162155}, {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64/comments/53896948.json"}, "html": {"href": "#!/dedalus-project/dedalus/issues/64#comment-53896948"}}, "issue": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus/issues/64.json"}}, "type": "issue", "id": 64, "repository": {"links": {"self": {"href": "data/repositories/dedalus-project/dedalus.json"}, "html": {"href": "#!/dedalus-project/dedalus"}, "avatar": {"href": "data/bytebucket.org/ravatar/{1dc39ab6-2798-450d-af2f-e976f94b5794}ts=2009435"}}, "type": "repository", "name": "dedalus", "full_name": "dedalus-project/dedalus", "uuid": "{1dc39ab6-2798-450d-af2f-e976f94b5794}"}, "title": "NCCs cause strange MPI crashes after commit 4232435 in 3D domains with distributed processor meshes"}, "content": {"raw": "Going to mark this fixed for now\u2026 please reopen if the issue comes up again!", "markup": "markdown", "html": "<p>Going to mark this fixed for now\u2026 please reopen if the issue comes up again!</p>", "type": "rendered"}, "created_on": "2019-09-13T15:16:09.902262+00:00", "user": {"display_name": "Keaton Burns", "uuid": "{3d3e64f1-bf12-45df-b655-4543d8fb34c4}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D"}, "html": {"href": "https://bitbucket.org/%7B3d3e64f1-bf12-45df-b655-4543d8fb34c4%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:e31a7835-5317-4dfa-8551-f32a06f40279/40f33f99-2b75-4a17-a8c2-07c8d74c7480/128"}}, "nickname": "kburns", "type": "user", "account_id": "557058:e31a7835-5317-4dfa-8551-f32a06f40279"}, "updated_on": null, "type": "issue_comment", "id": 53896948}], "page": 1, "size": 12}